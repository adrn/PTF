\documentclass[12pt,preprint]{aastex}
\newcounter{address}
\setcounter{address}{1}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{subfigure}
\usepackage{natbib}

\newcommand{\apwsim}{\raisebox{0.2ex}{\scriptsize$\sim$\normalsize}} 

\begin{document}

\title{Title Placeholder}
\author{
  Adrian~M.~Price-Whelan\altaffilmark{\ref{col}}, Marcel~Ag\"ueros\altaffilmark{\ref{col}}, Amanda Fournier\altaffilmark{\ref{ucsb}}, Eran Ofek\altaffilmark{\ref{weiz}}, Rachel Street\altaffilmark{\ref{lcogt}}
}

\altaffiltext{\theaddress}{\stepcounter{address}\label{col} Department of Astronomy, Columbia University, 550 W 120th St., New York, NY 10027, USA}
\altaffiltext{\theaddress}{\stepcounter{address}\label{ucsb} Department of Physics, Broida Hall, University of California, Santa Barbara, CA 93106, USA}
\altaffiltext{\theaddress}{\stepcounter{address}\label{weiz} Benoziyo Center for Astrophysics, Weizmann Institute of Science, 76100 Rehovot, Israel}
\altaffiltext{\theaddress}{\stepcounter{address}\label{lcogt} Las Cumbres Observatory Global Telescope Network, Inc., 6740 Cortona Dr.\ Suite 102, Santa Barbara, CA 93117, USA}

\begin{abstract}
	Many current photometric, time-domain surveys are driven by specific goals, such as supernova searches, transiting exoplanet discoveries, or stellar variability studies, which set the cadence with which individual fields get re-imaged. In the case of the Palomar Transient Factory (PTF), several such sub-surveys are being conducted in parallel, leading to an extremely non-uniform sampling gradient over the survey footprint of nearly 20,000 deg$^2$: while the typical 7.26~deg$^2$ PTF field has been imaged 15 times, \apwsim1000~deg$^2$ of the survey has been observed more than 150 times. We use the existing PTF data to study the trade-off between a large survey footprint and irregular sampling when searching for microlensing events, and to examine the probability that such events can be recovered in these data. We conduct Monte Carlo simulations to evaluate our detection efficiency in a hypothetical survey field as a function of both the baseline and number of observations. We also apply variability statistics to systematically differentiate between periodic, transient, and flat light curves. Preliminary results suggest that both recovery and discovery of microlensing events are possible with a careful consideration of photometric systematics. This work can help inform predictions about the observability of microlensing signals in future wide-field time-domain surveys such as that of LSST.
	
\end{abstract}

\keywords{
  survey science
  ---
  gravitational microlensing
  ---
  time-domain astrophysics
}

\section{Introduction}
Since Einstein first studied gravitational microlensing (cite), the phenomena has been used to study dark objects, probe galactic structure and kinematics, and discover extrasolar planets. Microlensing events were once relatively rare, but with advances in CCD technology and the help of several dedicated microlensing surveys (), $>500$ lensing events are now detected per observing season. 

[MORE MICROLENSING INTRODUCTION]

[QUICK INTRO TO THEORY AND JARGON]

[MOTIVATION FOR PROJECT -- Han, Di Stefano, Di Stefano et al. -- mesolensing and near-field microlensing]

\section{PTF Observations and Data}
[TODO: Marcel]

\section{Microlensing event recovery}
Microlensing surveys typically use difference image analysis (cite Lupton?) to initially identify transient events and then analyze the candidate light curves to search for microlensing events (cite MACHO, OGLE). This method is essential for studying crowded fields such as the Galactic bulge, and also limits the number of light curves that must be searched for microlensing events, thus saving on computation time. This [method] also provides real-time detection of events so surveys can utilize networks of telescopes to provide follow-up observations of these transients. Our approach is to instead take the preexisting PTF light curve database over the entire survey footprint and develop fast, robust search algorithms to pick out microlensing event candidates from this massive data archive.

In order to develop predictions for event rates and then eventually use observed event rates to infer [] we must understand our microlensing event recovery rate, or \textit{detection efficiency}, $\varepsilon$. The detection efficiency is commonly expressed as a function of microlensing event timescale and is therefore a function of survey parameters, such as cadence and baseline [FIGURE simulated detection efficiency]. [What did MACHO do exactly? What does OGLE do?] The nature of the PTF survey means that different fields are observed with very different sampling patterns [FIGURE showing different sampling]. We must compute the detection efficiency for each field individually.

We compute the detection efficiency with a Monte Carlo simulation over real data. For a particular field of interest, we randomly sample 11,000 light curves from the database with $>25$ ``good'' observations. [define ``good'']. We compute a set of variability statistics for each light curve, we then iterate and add 100 different simulated microlensing events to each light curve and recompute the variability statistics after each iteration [Figures here?]. The parameters for the random microlensing events are chosen as follows: 
\begin{align}
	t_0&\sim\mathcal{U}[t_{min}, t_{max}] \\
	u_0&\sim\mathcal{U}[0, 1] \\
	\log_{10}t_E&\sim\mathcal{U}[0, 3] 
\end{align}
where $\mathcal{U}$ is a uniform distribution.

[How to compute detection efficiency?] [Specifics of our method, e.g. details about my code]

[Parts of the above text will get absorbed into sections below]

\subsection{Selecting candidate microlensing events}
- Proper statistical modeling is too time consuming, so we first have to define some selection criteria to limit the sample (number of good observations, quality cuts, etc.)

- Discuss $\Delta \chi^2$ method, downfalls (speed, not robust -- how do you define the threshold?)

- Shin et al. paper

- Introduce variability statistics: define them, what they pick out, what they have been used for before

\subsection{Detection efficiency}
- Previous surveys had fairly uniform time sampling, and smaller areas

- With PTF, fields have vastly different sampling patterns, baselines, and cadences

- We have to consider the efficiency on a field-by-field basis

- Show detection efficiency of each variability statistic

\section{Searching for events in full PTF data set}
- Describe pipeline for events ... ?

\section{Comparing results to model predictions (?)}

\section{Conclusions and Future Work}
\subsection{Globular Clusters and Other Overdensities}
- Do they contribute to the lensing rate?

%\bibliographystyle{apj}
%\bibliography{apj-jour,refs}
%
%\begin{figure}
%	\centering
%	\caption{Computed detection efficiency as a function of number of observations for a fixed baseline of 365 days. This plot uses entirely simulated light curves.}
%    \includegraphics[width=1.0\textwidth]{figures/detection_efficiency_figure.pdf}
%    \label{fig:detection_eff}
%\end{figure}	
%
%\begin{figure}
%	\centering
%	\caption{A visualization of the different sampling regimes of six different PTF fields over the same one year baseline. Darker points mean more data (more exposures). Some fields have roughly uniform coverage, where others are very dense during some weeks and not others. }
%    \includegraphics[width=1.0\textwidth]{figures/ptf_sampling_figure.pdf}
%    \label{fig:light_curves}
%\end{figure}
%
%\begin{figure}
%	\centering
%	\caption{Example of how the variability indices may be used to separate microlensing events from periodic or flat light curves.}
%    \includegraphics[width=1.0\textwidth]{figures/J_vs_K_Con_figure.png}
%    \label{fig:var_idx1}
%\end{figure}
%
%\begin{figure}[htbp]
%	\centering
%	\caption{Two neighboring light curves. The time scale is the same on both plots. Note the strong similarities in the overall shapes of the data.} 
%	 \includegraphics[width=1.0\textwidth]{figures/bad_data_figure.pdf}
%	\label{fig:lc_correlated}
%\end{figure}

\end{document}  